{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from face_clustering_pipeline import FaceClusteringPipeline\n",
    "from helper.compare_w_reference import compare_w_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 40k baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline used will be strategy 0.512 (f1). The goal is to see if the\n",
    "iterative method have similar performance to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path(\"/media/bao/t7/la_lib_dataset\")\n",
    "\n",
    "src_folder = base_path / \"img\"\n",
    "faces_folder = base_path / \"faces\"\n",
    "save_folder = base_path / \"results_iterative_clustering\"\n",
    "\n",
    "df_folder = save_folder / \"df\"\n",
    "log_folder = save_folder / \"log\"\n",
    "\n",
    "df_folder.mkdir(exist_ok=True, parents=True)\n",
    "log_folder.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceClusteringPipeline = FaceClusteringPipeline(src_folder, faces_folder, df_folder, log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the (pre-computed) embeddings \n",
    "model_name = \"Facenet512\"\n",
    "df = pd.read_csv('/media/bao/t7/la_lib_dataset/results_dbscan/df/keep_representation_Facenet512.csv', index_col=0, converters={f\"{model_name}_representation\": json.loads})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:58<00:00, 17.86s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Clustering using the best f1 parameters\n",
    "min_samples = 5\n",
    "eps = 0.24 # threshold\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "times = []\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    df_input = df.copy()\n",
    "    # gen random number using numpy\n",
    "    random_state = np.random.randint(0, 1000)\n",
    "    df_input = df_input.sample(frac=1, random_state=random_state)\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    df_res = faceClusteringPipeline.p_cluster_faces(df_input, df_folder, model_name=model_name, clustering_algo=\"DBSCAN\", distance_metric=\"cosine\", min_samples=5, threshold=0.24, save=False)\n",
    "    total_t = perf_counter() - t0\n",
    "\n",
    "    # This column is needed to compare with the reference clusters\n",
    "    df_res[\"face_id\"] = df_res[\"image\"].apply(pathlib.Path).apply(lambda x: x.stem)\n",
    "\n",
    "    reference_clusters_path = pathlib.Path(\"../reference_clusters\")\n",
    "\n",
    "    total_tp, total_fn, total_fp, df_stats = compare_w_ref(reference_clusters_path, df_res, faces_folder=faces_folder, src_folder=src_folder)\n",
    "\n",
    "    total_precision = total_tp / (total_tp + total_fp)\n",
    "    total_recall = total_tp / (total_tp + total_fn)\n",
    "    total_f1 = 2 * (total_precision * total_recall) / (total_precision + total_recall)\n",
    "\n",
    "    # print(\"Total precision:\", total_precision)\n",
    "    # print(\"Total recall:\", total_recall)\n",
    "    # print(\"Total f1:\", total_f1)\n",
    "    precisions.append(total_precision)\n",
    "    recalls.append(total_recall)\n",
    "    f1s.append(total_f1)\n",
    "    times.append(total_t)\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    \"precision\": precisions,\n",
    "    \"recall\": recalls,\n",
    "    \"f1\": f1s,\n",
    "    \"time\": times\n",
    "})\n",
    "\n",
    "df_results.to_csv(f\"res/res_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All clusters in the outliers: [-1]\n",
      "All clusters in the re-clustering of the outliers: [-1]\n"
     ]
    }
   ],
   "source": [
    "# Re-clustering only the outliers (cluster_label == -1) should not produce any new cluster \n",
    "\n",
    "df_outliers = df_res[df_res[\"cluster_label\"] == -1].copy()\n",
    "\n",
    "print(\"All clusters in the outliers:\", df_outliers[\"cluster_label\"].unique())\n",
    "\n",
    "# re-clustering the outliers\n",
    "df_res_outliers = faceClusteringPipeline.p_cluster_faces(df_outliers, df_folder, model_name=model_name, clustering_algo=\"DBSCAN\", distance_metric=\"cosine\", min_samples=5, threshold=0.24, save=False)\n",
    "\n",
    "# There should be no new cluster\n",
    "print(\"All clusters in the re-clustering of the outliers:\", df_res_outliers[\"cluster_label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1      29094\n",
       " 0       2233\n",
       " 21       125\n",
       " 88        41\n",
       " 55        39\n",
       "        ...  \n",
       " 174        4\n",
       " 150        4\n",
       " 229        4\n",
       " 252        4\n",
       " 144        2\n",
       "Name: cluster_label, Length: 277, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res[\"cluster_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total precision: 0.9675785207700102\n",
      "Total recall: 0.9218146718146718\n",
      "Total f1: 0.944142362827484\n"
     ]
    }
   ],
   "source": [
    "# compute the baseline performance\n",
    "reference_clusters_path = pathlib.Path(\"../reference_clusters\")\n",
    "\n",
    "total_tp, total_fn, total_fp, df_stats = compare_w_ref(reference_clusters_path, df_res, faces_folder=faces_folder, src_folder=src_folder)\n",
    "\n",
    "total_precision = total_tp / (total_tp + total_fp)\n",
    "total_recall = total_tp / (total_tp + total_fn)\n",
    "total_f1 = 2 * (total_precision * total_recall) / (total_precision + total_recall)\n",
    "\n",
    "print(\"Total precision:\", total_precision)\n",
    "print(\"Total recall:\", total_recall)\n",
    "print(\"Total f1:\", total_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('snowflakes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01f49e0e7f49e8c39b51c5bad5f7f78046f883f46ef3b19f9dfb3452a1233494"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
